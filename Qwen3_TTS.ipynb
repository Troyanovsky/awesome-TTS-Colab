{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Troyanovsky/awesome-TTS-Colab/blob/main/Qwen3_TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B51gJgKjOsd"
      },
      "source": [
        "# üó£Ô∏è Qwen3-TTS Colab\n",
        "\n",
        "## üìÑ Description\n",
        "\n",
        "This Colab notebook runs **Qwen3-TTS-12Hz-0.6B-Base** and **Qwen3-TTS-12Hz-1.7B-Base**, powerful **multilingual, low-latency text-to-speech (TTS)** models from the **Qwen3 TTS family**.\n",
        "Designed with a **universal end-to-end architecture**, Qwen3-TTS delivers **high-fidelity**, **instruction-controllable**, and **real-time streaming** speech synthesis with strong robustness to noisy or complex text inputs.\n",
        "\n",
        "**Capabilities:**\n",
        "Multilingual TTS (10 Languages), Ultra-Low-Latency Streaming (‚âà97ms), Instruction-Based Voice Control, Rapid 3s Voice Cloning, High-Fidelity Speech Reconstruction\n",
        "\n",
        "---\n",
        "\n",
        "## How to use\n",
        "\n",
        "* Modify text and instruction variables\n",
        "* Run all following cells, upload reference audio if needed, and generate speech\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Model Highlights\n",
        "\n",
        "* üåç **10-language support** ‚Äì Chinese, English, Japanese, Korean, German, French, Russian, Portuguese, Spanish, Italian\n",
        "* ‚ö° **Extreme low-latency generation** ‚Äì first audio packet emitted after a single character input\n",
        "* üß† **Instruction-aware speech synthesis** ‚Äì adaptive control over tone, emotion, prosody, and speaking rate\n",
        "* üß¨ **3-second rapid voice cloning** ‚Äì supported by both Base models\n",
        "* üèó **End-to-end discrete LM architecture** ‚Äì avoids cascading errors of traditional TTS pipelines\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Model Details\n",
        "\n",
        "* **Models Included:** Qwen3-TTS-12Hz-0.6B-Base, Qwen3-TTS-12Hz-1.7B-Base\n",
        "* **Speech Tokenizer:** Qwen3-TTS-Tokenizer-12Hz\n",
        "* **Architecture:** Discrete multi-codebook LM (non-DiT)\n",
        "* **Streaming Support:** Yes (streaming & non-streaming in one model)\n",
        "* **Latency:** As low as ~97 ms end-to-end\n",
        "* **Use Cases:** Real-time assistants, voice agents, multilingual narration, TTS fine-tuning\n",
        "\n",
        "---\n",
        "\n",
        "## üîó Resources\n",
        "\n",
        "* **Hugging Face (1.7B):** https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base  \n",
        "* **Hugging Face (0.6B):** https://huggingface.co/Qwen/Qwen3-TTS-12Hz-0.6B-Base  \n",
        "* **Official Blog:** https://qwen.ai/blog\n",
        "\n",
        "---\n",
        "\n",
        "## üéôÔ∏è Explore More TTS Models\n",
        "\n",
        "Looking for more cutting-edge voice models?\n",
        "üëâ Check out the full collection: [awesome-TTS-Colab](https://github.com/Troyanovsky/awesome-TTS-Colab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px0vNqaD_sNt"
      },
      "source": [
        "## TTS/Voice Generation with Voice Cloning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U qwen-tts soundfile\n",
        "\n",
        "# (Optional, recommended on GPU) FlashAttention 2 for lower memory + faster attention.\n",
        "# If this fails (GPU not compatible / build issues), the notebook will still run without it.\n",
        "try:\n",
        "    import flash_attn  # noqa: F401\n",
        "    print(\"flash-attn already installed.\")\n",
        "except Exception:\n",
        "    !pip -q install -U flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "t8360fxIrq84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from qwen_tts import Qwen3TTSModel\n",
        "\n",
        "MODEL_ID = \"Qwen/Qwen3-TTS-12Hz-0.6B-Base\" # or \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\"\n",
        "LANGUAGE = \"English\"  # e.g., Chinese, English, Japanese, Korean, German, French, Russian, Portuguese, Spanish, Italian\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "attn_impl = \"flash_attention_2\" if torch.cuda.is_available() else None\n",
        "\n",
        "model = Qwen3TTSModel.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    device_map=device,\n",
        "    dtype=dtype,\n",
        "    attn_implementation=attn_impl,\n",
        ")\n",
        "\n",
        "print(f\"Loaded {MODEL_ID} on {device} with dtype={dtype} attn={attn_impl}\")\n"
      ],
      "metadata": {
        "id": "_u_EyN5Mrwlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # upload a .wav/.mp3/.flac etc.\n",
        "ref_audio_path = next(iter(uploaded.keys()))\n",
        "print(\"Reference audio:\", ref_audio_path)\n",
        "\n",
        "ref_text = \"I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.\"\n",
        "# Tip: For best cloning quality, make this transcript match the reference audio as closely as possible."
      ],
      "metadata": {
        "id": "hsrhW-P5r2eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "\n",
        "input_text = \"This is a cloned voice demo generated with Qwen3-TTS in Google Colab.\"\n",
        "\n",
        "out_clone_path = \"output_voice_clone.wav\"\n",
        "\n",
        "wavs, sr = model.generate_voice_clone(\n",
        "    text=input_text,\n",
        "    language=LANGUAGE,\n",
        "    ref_audio=ref_audio_path,\n",
        "    ref_text=ref_text,\n",
        "    # If you don't want to provide ref_text, set x_vector_only_mode=True (may reduce quality):\n",
        "    # x_vector_only_mode=True,\n",
        ")\n",
        "\n",
        "sf.write(out_clone_path, wavs[0], sr)\n",
        "print(\"Saved:\", out_clone_path, \"| sr:\", sr)"
      ],
      "metadata": {
        "id": "6JnjfU-1sH_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio, display\n",
        "\n",
        "display(Audio(out_clone_path))"
      ],
      "metadata": {
        "id": "UAeory9GsPI8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNOFg1n0gyraE4aeekAgk/t",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}