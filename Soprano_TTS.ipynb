{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Troyanovsky/awesome-TTS-Colab/blob/main/Soprano_TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B51gJgKjOsd"
      },
      "source": [
        "# ðŸŽ¶ Soprano Colab\n",
        "\n",
        "## ðŸ“„ Description\n",
        "\n",
        "This Colab notebook runs **Soprano**, an **ultra-lightweight, ultra-fast text-to-speech (TTS)** model built for **real-time, high-fidelity speech synthesis**.\n",
        "With only **80M parameters**, Soprano achieves **~2000Ã— real-time factor (RTF)**â€”capable of generating **10 hours of audio in under 20 seconds**, while supporting **true streaming synthesis (<15 ms latency)**.\n",
        "\n",
        "**Capabilities:**\n",
        "Ultra-Fast Real-Time TTS, 32 kHz High-Fidelity Audio, Streaming Inference, Lightweight Deployment, Open-Source\n",
        "\n",
        "---\n",
        "\n",
        "## How to use\n",
        "\n",
        "* Modify the input text variable  \n",
        "* Run all cells to generate audio output  \n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ Model Highlights\n",
        "\n",
        "* ðŸŽ§ **High-fidelity 32 kHz audio** â€“ perceptually comparable to 44.1 kHz and significantly higher quality than typical 24 kHz TTS\n",
        "* âš¡ **Extremely fast inference** â€“ ~2000Ã— real-time generation with minimal compute overhead  \n",
        "* ðŸ”Š **Vocos-based neural decoder** â€“ replaces diffusion for orders-of-magnitude faster waveform synthesis  \n",
        "* ðŸ”„ **Seamless real-time streaming** â€“ sub-frame latency with identical quality to offline generation  \n",
        "* ðŸ§  **Efficient neural audio codec** â€“ ~15 tokens/sec at ~0.2 kbps for fast, memory-efficient synthesis  \n",
        "* â™¾ï¸ **Sentence-level streaming** â€“ enables effectively infinite-length generation with stable real-time performance  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Model Details\n",
        "\n",
        "* **Base Model:** Qwen3 (LLM backbone)  \n",
        "* **Decoder:** Vocos (fine-tuned on LLM hidden states)  \n",
        "* **Model Size:** 80M parameters  \n",
        "* **Supported Language:** English  \n",
        "* **Performance:** ~2000Ã— RTF, real-time streaming capable  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”— Resources\n",
        "\n",
        "* **GitHub Repository:** https://github.com/ekwek1/soprano  \n",
        "* **Model Availability:** https://huggingface.co/ekwek/Soprano-80M  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ™ï¸ Explore More TTS Models\n",
        "\n",
        "Looking for more cutting-edge voice models?  \n",
        "ðŸ‘‰ Check out the full collection: [awesome-TTS-Colab](https://github.com/Troyanovsky/awesome-TTS-Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px0vNqaD_sNt"
      },
      "source": [
        "## Basic TTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y rasterio rasterstats\n",
        "!git clone https://github.com/ekwek1/soprano.git\n",
        "%cd soprano\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "03hfmXnqp3JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/soprano/\n",
        "from soprano import SopranoTTS\n",
        "from IPython.display import Audio, display\n",
        "import os\n",
        "\n",
        "# Configure input + output\n",
        "input_text = \"Hello world! This is Soprano speaking.\"\n",
        "out_wav = \"soprano_out.wav\"\n",
        "\n",
        "# Optional sampling params (tweak or leave as-is)\n",
        "temperature = 0.3\n",
        "top_p = 0.95\n",
        "repetition_penalty = 1.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UItasSZBp3eY",
        "outputId": "6f9e2e18-feeb-42d3-879d-67b16b1a8910"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/soprano\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SopranoTTS()\n",
        "_ = model.infer(\n",
        "    input_text,\n",
        "    out_wav,\n",
        "    temperature=temperature,\n",
        "    top_p=top_p,\n",
        "    repetition_penalty=repetition_penalty,\n",
        ")\n",
        "\n",
        "print(f\"Saved: {os.path.abspath(out_wav)}\")"
      ],
      "metadata": {
        "id": "re0b5OtCp-MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play audio inline\n",
        "display(Audio(out_wav))"
      ],
      "metadata": {
        "id": "7m0hD4hvqBX9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPuKR2sUbSXlM/31t1pY50Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}